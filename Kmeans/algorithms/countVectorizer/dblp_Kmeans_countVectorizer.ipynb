{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dictionary of title_Id -> title_name\n",
    "fp=open(\"title_Id.txt\",'r')\n",
    "\n",
    "titleId_titleName={}\n",
    "for line in fp:\n",
    "    line=line.strip().split('#')\n",
    "    #print line[0], line[1]\n",
    "    if len(line)!=2:\n",
    "        if len(line)>2:\n",
    "            key=line[-1]\n",
    "            value=\"\"\n",
    "            for i in range(len(line)-1):\n",
    "                value=value+line[i]\n",
    "            titleId_titleName[key]=value \n",
    "    else:\n",
    "        titleId_titleName[line[1]]=line[0]\n",
    "\n",
    "fp.close()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dictionary of journal_Id -> journal_name\n",
    "fp=open(\"journal_Id.txt\",'r')\n",
    "\n",
    "journalId_JournalName={}\n",
    "for line in fp:\n",
    "    line=line.strip().split(\"#\")\n",
    "    journalId_JournalName[line[1]]=line[0]\n",
    "\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dictionary of author_Id -> author_name\n",
    "fp= open(\"author_Id.txt\",'r')\n",
    "\n",
    "authorId_authorName={}\n",
    "for line in fp:\n",
    "    line = line.strip().split(\"#\")\n",
    "    authorId_authorName[line[1]]=line[0]\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fp= open(\"title_Journal_Author.txt\",'r')\n",
    "\n",
    "authorList=[]\n",
    "titleJournalList=[]\n",
    "for line in fp:\n",
    "    line = line.strip().split(\"#\")\n",
    "    curr= titleId_titleName[line[0]] + \" \" + journalId_JournalName[line[1]]\n",
    "    titleJournalList.append(curr)\n",
    "    tempList=line[2].strip().split('|') #author ids list\n",
    "    tempNameList=[] #authors namelist\n",
    "    for i in tempList:\n",
    "        tempNameList.append(authorId_authorName[i])\n",
    "    authorList.append(tempNameList)\n",
    "    \n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print len(authorList)\n",
    "#print len(titleJournalList)\n",
    "#print authorList[2], titleJournalList[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125296\n"
     ]
    }
   ],
   "source": [
    "# to find a no. of unique words\n",
    "vocab={}\n",
    "for line in titleJournalList:\n",
    "    wordList=line.strip().split()\n",
    "    for word in wordList:\n",
    "        if word in vocab:\n",
    "            vocab[word]=vocab[word]+1\n",
    "        else:\n",
    "            vocab[word]=1\n",
    "\n",
    "print len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None, stop_words = 'english', max_features = 70000)\n",
    "vec=vectorizer.fit(titleJournalList)\n",
    "vectorized=vec.transform(titleJournalList)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(analyzer='word', binary=False, decode_error=u'strict',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=70000, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)\n"
     ]
    }
   ],
   "source": [
    "print vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print type(vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=100,\n",
       "    n_clusters=20, n_init=1, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km = KMeans(n_clusters=20, init='k-means++', max_iter=100, n_init=1)\n",
    "km.fit(vectorized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0:  models  graphical  comput  based  physics  using  logic  automatica  petri  nets\n",
      "Cluster 1:  synthese  theory  logic  epistemic  knowledge  problem  science  explanation  truth  scientific\n",
      "Cluster 2:  based  syst  knowl  knowledge  using  systems  fuzzy  approach  model  data\n",
      "Cluster 3:  comput  physics  based  journal  computer  reliability  computing  logic  using  networks\n",
      "Cluster 4:  generation  future  comp  syst  based  grid  data  parallel  computing  distributed\n",
      "Cluster 5:  fuzzy  systems  intelligent  journal  based  using  decision  control  making  method\n",
      "Cluster 6:  web  agent  intelligence  systems  based  multi  information  agents  social  using\n",
      "Cluster 7:  safety  eng  amp  sys  rel  analysis  systems  risk  based  model\n",
      "Cluster 8:  acm  trans  secur  inf  syst  based  control  access  systems  secure\n",
      "Cluster 9:  appl  eng  ai  commun  algebra  comput  based  using  fuzzy  algorithm\n",
      "Cluster 10:  safety  reliability  eng  amp  sys  rel  analysis  systems  based  using\n",
      "Cluster 11:  log  math  logic  algebras  sets  theory  theorem  constructive  models  arithmetic\n",
      "Cluster 12:  decision  support  systems  based  information  management  model  knowledge  approach  analysis\n",
      "Cluster 13:  data  analysis  computational  amp  statistics  computing  scientific  siam  models  method\n",
      "Cluster 14:  engineering  software  journal  knowledge  international  based  ieee  systems  using  development\n",
      "Cluster 15:  systems  automatica  journal  computers  circuits  control  operating  review  based  time\n",
      "Cluster 16:  ieee  transactions  neural  networks  security  information  privacy  amp  forensics  technology\n",
      "Cluster 17:  imaging  medical  bmc  using  study  magnetic  resonance  analysis  ct  patients\n",
      "Cluster 18:  algorithmica  algorithms  algorithm  graphs  problem  problems  time  trees  parallel  approximation\n",
      "Cluster 19:  ieee  trans  syst  data  vlsi  eng  knowl  learning  neural  based\n"
     ]
    }
   ],
   "source": [
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i in range(20):\n",
    "    print \"Cluster %d:\" % i,\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print ' %s' % terms[ind],\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "authorClusters={} # Cluster Id to List of authorName\n",
    "for i in range(len(titleJournalList)):\n",
    "    currList=[]\n",
    "    currList.append(titleJournalList[i])\n",
    "    data_features=vec.transform(currList)\n",
    "    labels=km.predict(data_features)\n",
    "    \n",
    "    clusterId=labels[0]\n",
    "    curAuthorsList=authorList[i] #authors list for current article\n",
    "    if clusterId in authorClusters.keys():\n",
    "        #fetch the existing list of authors for the clusterId\n",
    "        tempList=authorClusters[clusterId]\n",
    "        for j in curAuthorsList:\n",
    "            tempList.append(j)\n",
    "            \n",
    "        #update authorsClusters with updated authors list\n",
    "        authorClusters[clusterId]=tempList\n",
    "        \n",
    "    else: #create a new key with the new cluster id and make value list of authors for the current article\n",
    "        authorClusters[clusterId]=curAuthorsList\n",
    "\n",
    "# print clusters Id-> author ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'authorClusters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f231bae4bc13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Kmeans_countVectorizer_output\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"wr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mauthorClusters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0moutstr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" => \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthorClusters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutstr\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'authorClusters' is not defined"
     ]
    }
   ],
   "source": [
    "fp=open(\"Kmeans_countVectorizer_output\",\"wr\")\n",
    "\n",
    "for i in authorClusters.keys():\n",
    "    outstr=str(i) + \" => \" + str(authorClusters[i])\n",
    "    fp.write(outstr+\"\\n\")\n",
    "    fp.write(\"**************************************************************************************************************************\"+\"\\n\")\n",
    "fp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
